---
title: "Insights - Tabela de Dados da Aeronaútica"
author: "Gabriel Marreiros"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    highlight: kate
---

```{r rmarkdown_setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)

# Pacotes
library(data.table) # Framework de manipulação dos dados
library(echarts4r) # Framework de visualização de séries temporais
```

# Introdução

A ideia desse documento é pegar um dataset com qual não tenho familiaridade e tentar extrair algum tipo de *insight* ou algum fato interessante usando R, usando especialmente data.table, Rmarkdown para compilar um documento de como fui me mergulhando nos dados junto com alguns htmlwidgets no caminho, e possivelmente criar um demo de um aplicativo shiny no final.

Nesse caso, escolhi um dataset que me interessou sobre **Ocorrências Aeronáuticas na Aviação Civil Brasileira**. Imagino que terá como mexer um pouco com mapas usando Leatlet ou alguma outra direção que quisermos tomar. 

Esses datasets são extraídos da CENIPA e estão disponíveis no [site de dados abertos do Governo Federal](https://dados.gov.br/dataset/ocorrencias-aeronauticas-da-aviacao-civil-brasileira).

Segue uma breve descrição do que está no site: 

> A base de dados de ocorrências aeronáuticas é gerenciada pelo Centro de Investigação e Prevenção de Acidentes Aeronáuticos (CENIPA). Constam nesta base de dados as ocorrências aeronáuticas notificadas ao CENIPA nos últimos 10 anos e que ocorreram em solo brasileiro.

> Dentre as informações disponíveis estão os dados sobre as aeronaves envolvidas, fatalidades, local, data, horário dos eventos e informações taxonômicas típicas das investigações de acidentes (AIG). São resguardadas a privacidade de pessoas físicas/jurídicas envolvidas conforme previsto pela Lei de Acesso à Informação (Lei n° 12.527, de 18 de novembro de 2011). 

- Informações dos dados utilizados nesse relatório:

| **Campo**                 | **Valor**                                                                                                                            |
|---------------------------|--------------------------------------------------------------------------------------------------------------------------------------|
| Fonte                     | http://www.fab.mil.br/cenipa/                                                                                                        |
| Autor                     | Centro de Investigação e Prevenção de Acidentes Aeronáuticos                                                                         |
| Mantenedor                | Centro de Investigação e Prevenção de Acidentes Aeronáuticos                                                                         |
| Versão                    | 1.3                                                                                                                                  |
| Última Atualização        | 5 de Outubro de 2021, 19:19 (UTC-03:00)                                                                                              |
| Criado                    | 1 de Junho de 2015, 15:37 (UTC-03:00)                                                                                                |
| Cobertura geográfica      | Brasil                                                                                                                               |
| Cobertura temporal        | 2010 a 2019                                                                                                                          |
| Fale Conosco              | estatistica.cenipa@fab.mil.br                                                                                                        |
| Frequência de atualização | Anual                                                                                                                                |
| Granularidade geográfica  | Aeródromo                                                                                                                            |
| Granularidade temporal    | Hora:Minuto                                                                                                                          |
| VCGE                      | Aeronáutica [http://vocab.e.gov.br/2011/03/vcge#aeronautica], Transporte Aéreo [http://vocab.e.gov.br/2011/03/vcge#transporte-aereo] |

---

# Importação e Tratamentos Iniciais dos Dados

## Importação dos Dados

Bom, iniciei o programa importando as informações do portal da CENIPA (Centro de Investigação e Prevenção de Acidentes Aeronáuticos) encontrados no link mencionados na Introdução.

Note que se importarmos o programa sem especificar o encoding como "UTF-8", então caracteres especiais do Português Brasil serão lidos incorretamente. e.g. "ã", "é", "Ç", etc.

<!-- Importa tabelas do portal de dados abertos do Governo Federal -->
<!-- https://dados.gov.br/dataset/ocorrencias-aeronauticas-da-aviacao-civil-brasileira -->
```{r Importando dados da CENIPA, echo=FALSE}
# Tabela Central - Ocorrência
ocorrencia <- data.table::fread(
  "http://sistema.cenipa.aer.mil.br/cenipa/media/opendata/ocorrencia.csv",
  encoding = "UTF-8"
)

# Tabela Complementar 1 - Código de Ocorrência 1
ocorrencia_tipo <- data.table::fread(
  "http://sistema.cenipa.aer.mil.br/cenipa/media/opendata/ocorrencia_tipo.csv",
  encoding = "UTF-8"
)

# Tabela Complementar 2 - Código de Ocorrência 2
aeronave <- data.table::fread(
  "http://sistema.cenipa.aer.mil.br/cenipa/media/opendata/aeronave.csv",
  encoding = "UTF-8"
)

# Tabela Complementar 3 - Código de Ocorrência 3
fator_contribuinte <- data.table::fread(
  "http://sistema.cenipa.aer.mil.br/cenipa/media/opendata/fator_contribuinte.csv",
  encoding = "UTF-8"
)

# Tabela Complementar 4 - Código de Ocorrência 4
recomendacao <- data.table::fread(
  "http://sistema.cenipa.aer.mil.br/cenipa/media/opendata/recomendacao.csv",
  encoding = "UTF-8"
)
```


## Cruzamento dos Dados

### Explicação

Normalmente, essa seria um bom momento de dar uma olhada em algumas colunas e ver o que podemos fazer com elas. No entanto, lendo as informações no site de dados do Governo Federal, notei que apesar de termos 5 tabelas diferentes, há uma tabela "central" que possui informações adicionais distribuídas nas outras 4, assim como na imagem a seguir:

![Relacionamento de dados das tabelas que usaremos](http://sistema.cenipa.aer.mil.br/cenipa/media/opendata/modelo_dados.png "Deve ser simples, certo?")
Como as tabelas são bem pequenas, com menos 10 mil linhas e 30 colunas, cruzá-las e trazer todas as informações em um único dataset poderá facilitar o tratamento de dados mais para frente. Talvez fique um pouco mais difícil de ter uma panorama geral só batendo o olho, mas dado o número colunas parece ser algo tolerável.

Como estou usando o pacote data.table, utilizarei-o para cruzar as informações baseado na chave seguindo a imagem do relacionamento de dados das tabelas acima. Extraindo as informações da imagem acima, seria algo assim:

```{r Criando tabela de exemplo 1, echo=FALSE}
nome_tabelas_complementares = list("OCORRENCIA_TIPO", "AERONAVE", "FATOR_CONTRIBUINTE", "RECOMENDACAO")
chave_tabelas_complementares = list("codigo_ocorrencia1", "codigo_ocorrencia2", "codigo_ocorrencia3", "codigo_ocorrencia4")

reactable::reactable(data.table::data.table(nome_tabelas_complementares, chave_tabelas_complementares))
```

### Cruzamento

#### Achados sobre a chave

Primeira coisa, dei um head para ter um panorama geral da tabela central, *ocorrencia* - especialmente das chaves. Nunca se sabe se algo deu errado.

```{r Head da chave da base Ocorrencia antes do cruzamento}
head(ocorrencia[, c("codigo_ocorrencia", "codigo_ocorrencia1", "codigo_ocorrencia2", "codigo_ocorrencia3", "codigo_ocorrencia4")])
```

Opa! Olhando o header, parece que ocorreu algo peculiar. As 5 primeiras linhas das 5 chaves possuem o valor idêntico!

Note que isso não significa que todas as linhas serão iguais. Porém, há uma leve suspeita para saber se isso é muito mais que uma mera coincidência, ou seja, que realmente esteja assim na tabela inteira.

Para checarmos no R se as colunas possuem valores iguais, podemos usar a função *identical* para saber se os elementos são iguais.

```{r Checagem 1 - Colunas das chaves são idênticas}
identical(
  ocorrencia[, codigo_ocorrencia], 
  ocorrencia[, codigo_ocorrencia1], 
  ocorrencia[, codigo_ocorrencia2],
  ocorrencia[, codigo_ocorrencia3],
  ocorrencia[, codigo_ocorrencia4]
)
```

E olha só! As colunas são de fato idênticas! Pode ser que um dia essas colunas sejam diferentes por algum motivo no site, mas no momento de nossa análise elas são idênticas.

Isso não mudará muita coisa no nosso cruzamento, mas isso significa que podemos descartar alguns dados mais para frente após o cruzamento.

#### Cruzando as tabelas

Voltando ao que interessa, vamos para o cruzamento. Tentarei fazer 4 left joins seguidos trazendo as informações das 4 tabelas complementares para a tabela central, *ocorrencia*:

```{r}
cruzamento1 <- ocorrencia[ocorrencia_tipo, on = "codigo_ocorrencia1"] # Left Join 1
cruzamento2 <- cruzamento1[aeronave, on = "codigo_ocorrencia2"] # Left Join 2
cruzamento3 <- cruzamento2[fator_contribuinte, on = "codigo_ocorrencia3"] # Left Join 3
# tabela <- cruzamento3[recomendacao, on = "codigo_ocorrencia4"] # Left Join 4
```

Rodando o código acima sem a última linha estar comentada, obtive um erro vindo do último cruzamento, um left join entre *ocorrencia* e *recomendacao*:

> Error in vecseq(f__, len__, if (allow.cartesian || notjoin || !anyDuplicated(f__, : 
Join results in 11387 rows; more than 6687 = nrow(x)+nrow(i). Check for duplicate key values in i each of which join to the same group in x over and over again. If that's ok, try by=.EACHI to run j for each group to avoid the large allocation. If you are sure you wish to proceed, rerun with allow.cartesian=TRUE. Otherwise, please search for this error message in the FAQ, Wiki, Stack Overflow and data.table issue tracker for advice.

#### Será que são chaves mesmo?

Aparentemente as chaves de alguma das duas tabelas não são únicas. Vamos dar uma olhadinha na frequências das chaves (código de ocorrência - *codigo_ocorrencia*) das tabelas:

```{r}
head(ocorrencia[, .(n = .N), by = codigo_ocorrencia][n > 1][order(-n)])
```

```{r}
head(ocorrencia_tipo[, .(n = .N), by = codigo_ocorrencia1][n > 1][order(-n)])
```

```{r}
head(aeronave[, .(n = .N), by = codigo_ocorrencia2][n > 1][order(-n)])
```

```{r}
head(fator_contribuinte[, .(n = .N), by = codigo_ocorrencia3][n > 1][order(-n)])
```

```{r}
head(recomendacao[, .(n = .N), by = codigo_ocorrencia4][n > 1][order(-n)])
```

Bom, dado que não há uma chave comum entre as tabelas que não estejam duplicadas, não é possível fazer um join simples entre elas como eu gostaria de ter feito. No entanto, como as tabelas não possuem nenhum campo de valor que poderíamos agregar (exceto 3 colunas que contém o nome "total" de frequência, mas que podem ser recalculadas usando as variáveis de origem), é possível fazer algo ainda que nos ajude a colocar tudo numa tabela só, usando cruzamento cartesiano (*cartesian join*).

#### Cruzamento Cartesiano

Fazer isso fará com que a tabela após os cruzamentos deixe de ter uma única chave, mas dado que irei sumarizar ela posteriormente com apenas uma seleção das colunas, deve dar tudo certo. 

Então, para fazer o cruzamento cartesiano no data.table basta especificar o argumento no final. Vamos ver se agora dará certo...

```{r}
cruzamento1 <- ocorrencia_tipo[ocorrencia, on = "codigo_ocorrencia1", allow.cartesian = TRUE] # Left Join 1
cruzamento2 <- aeronave[cruzamento1, on = "codigo_ocorrencia2", allow.cartesian = TRUE] # Left Join 2
cruzamento3 <- fator_contribuinte[cruzamento2, on = "codigo_ocorrencia3", allow.cartesian = TRUE] # Left Join 3
tabela <- recomendacao[cruzamento3, on = "codigo_ocorrencia4", allow.cartesian = TRUE] # Left Join 4

head(tabela)
```

E sucesso! 

*Wheeeew.* 

Agora que tenho uma tabela com todas as informações que preciso, posso criar algumas visões para tirar alguns insights ou análises interessantes sobre. Claro, após tratarmos alguns pontos dela :)

## Tratamento dos Dados

### Reordenação das Colunas

Para começar os tratamentos dos dados, reordenarei as colunas para ficar na ordem das bases que foram cruzadas, ou seja, na seguinte ordem:

1. ocorrencia;
2. ocorrencia_tipo;
3. aeronave;
4. fator_contribuinte;
5. recomendacao;

Lembrando que como as colunas *codigo_ocorrencia1*, *codigo_ocorrencia2*, *codigo_ocorrencia3*, *codigo_ocorrencia4* já existiam na tabela "central", *ocorrencia*, irei removê-las para evitar algum tipo de mal entendido no vetor.

```{r}
# Extrai o nome (e a ordem) das colunas pré cruzamento
colunas0 <- names(ocorrencia)
colunas1 <- names(ocorrencia_tipo)[2:length(names(ocorrencia_tipo))] # Eliminando a coluna de codigo_ocorrencia1
colunas2 <- names(aeronave)[2:length(names(aeronave))] # Eliminando a coluna de codigo_ocorrencia2
colunas3 <- names(fator_contribuinte)[2:length(names(fator_contribuinte))] # Eliminando a coluna de codigo_ocorrencia3
colunas4 <- names(recomendacao)[2:length(names(recomendacao))] # Eliminando a coluna de codigo_ocorrencia4

# Concatena os nomes das colunas
ordem_colunas <- c(colunas0, colunas1, colunas2, colunas3, colunas4)

# Atualiza a ordem na tabela por referência
data.table::setcolorder(tabela, ordem_colunas)
```


### Conversão das Colunas

Após a ordenação, posso finalmente começar a dar uma olhada na tabela "analítica" (pós-cruzamento das tabelas) carinhosamente chamada de *tabela*. Vamos dar uma olhadinha:

```{r}
str(tabela)
```

Hmm...

Analisando com calma a tabela, podemos anotar alguns pontos estranhos:

* De cara, dá para ver algumas colunas que não eram para ser texto: *aeronave_ano_fabricacao*, *ocorrencia_latitude*, *ocorrencia_dia*, etc;
  - Não appenas isso: dentre essas colunas, algumas precisam ser convertidas para número enquanto outras para data;
  
* Além disso, nossa tabela possui alguns valores estranhos como "***", "NULL" (literalmente como texto, não como valor booleano), que irei inferir que são __Missing__ já que não possuo metadados sobre o dataset.

Como os valores missing influenciará na conversão dos dados de texto para outros tipos, então começarei tratando eles primeiro.


#### Corrigindo os valores missing

Para corrigir os valores missing das colunas que são do tipo Texto, primeiro:

* Filtramos todas as colunas que são texto;

* E depois, caso algum elemento se encaixe em alguns dos valores estranhos que vimos, transformamos em missing (NA). e.g. "***", "NULL", etc.

Então, temos:

```{r}
# Seleciona as colunas que são do tipo character (texto), e guarda na colunas_texto
indices_colunas_texto <- which(unlist(lapply(tabela, is.character)))
colunas_texto <- names(tabela)[indices_colunas_texto]

# Para cada coluna do colunas_texto, troca o valor estranho para missing (NA) usando ifelse
tabela[, (colunas_texto) := lapply(.SD, function(x) ifelse(
  x == "***" 
  | x == "****" 
  | x == "*****"
  | x == "******"
  | x == "*******"
  | x == "********"
  | x == "*********"
  | x == "****_***"
  | x == "****_****"
  | x == "NULL" 
  | x == "", 
  NA, x)), .SDcols = colunas_texto]
```


#### Texto para datas

As colunas que deveriam ser do tipo Data contém "dia" no nome:

```{r}
names(tabela)[grepl("*dia", names(tabela))]
```

```{r}
de_texto_para_data <- names(tabela)[grepl("*dia", names(tabela))]
str(tabela[, ..de_texto_para_data])
```

Logo, para converter, basta aplicarmos o as.IDate - que é essencialmente o Date normal do R, mas compatível com o data.table.

Só um ponto de atenção: a variável *ocorrencia_dia* não só está como texto quanto também está em um formato de data diferente das demais. Tirando isso, as coisas estão dando tudo certo!

```{r}
# Converte somente a coluna ocorrencia_dia por ter um formato diferente (DD/MM/YYYY) 
tabela[, ocorrencia_dia := as.IDate(ocorrencia_dia, "%d/%m/%Y")]

# Converte colunas que possuem o formato (YYYY-MM-DD) 
tabela[, `:=`(
  divulgacao_dia_publicacao = as.IDate(divulgacao_dia_publicacao, "%Y-%m-%d"),
  recomendacao_dia_assinatura = as.IDate(recomendacao_dia_assinatura, "%Y-%m-%d"),
  recomendacao_dia_encaminhamento = as.IDate(recomendacao_dia_encaminhamento, "%Y-%m-%d"),
  recomendacao_dia_feedback = as.IDate(recomendacao_dia_feedback, "%Y-%m-%d")
)]

# Converte a coluna ocorrencia_hora para o formato ITime 
tabela[, ocorrencia_hora := as.ITime(ocorrencia_hora, "%d/%m/%Y")]
```


#### Texto para numérico/inteiro

Agora para o caso de ver qual variável deveria ser numérica, não tem jeito. Como o número é pequeno, dá para darmos uma olhada olhando no "str(tabela)" acima.

* ocorrencia_latitude;
* ocorrencia_longitude;
* aeronave_assentos;
* aeronave_ano_fabricacao;

Sabendo quais são as colunas, basta convertê-las:

```{r}
colunas_texto_para_numero <- c(
"ocorrencia_latitude",
"ocorrencia_longitude",
"aeronave_assentos",
"aeronave_ano_fabricacao"
)

# tabela[, (colunas_texto_para_numero) := lapply(.SD, function(x) as.numeric(x)), .SDcols = colunas_texto_para_numero]
```

Ou pelo menos deveria ser! Tentando converter as 4 colunas de uma vez retorna erro em 2 colunas - que estão aplicando NA por *coercion*, ou seja, por não saber converter. Olhando mais afundo, notamos que o problema ocorre  nas colunas de latitude e longitude. Portanto, vamos converter as outras duas que deram certo, *aeronave_assentos* e *aeronave_assentos*, e ver mais a fundo o caso do da latitude e longitude.

```{r}
tabela[, `:=`(
  aeronave_assentos = as.numeric(aeronave_assentos),
  aeronave_ano_fabricacao = as.numeric(aeronave_ano_fabricacao)
)]
```


#### Latitude e Longitude

Texto

<!-- Check that the first number in your latitude coordinate is between -90 and 90. -->
<!-- Check that the first number in your longitude coordinate is between -180 and 180. -->


##### Astericos
```{r}
# Observações que ainda possuem asteriscos
unique(tabela$ocorrencia_latitude)[grepl("\\*", unique(tabela$ocorrencia_latitude))]
```
```{r}
# Observações que ainda possuem asteriscos
unique(tabela$ocorrencia_longitude)[grepl("\\*", unique(tabela$ocorrencia_longitude))]
```

##### Outros casos peculiares
```{r}
head(sort(unique(tabela[, ocorrencia_latitude])), 135)
```

```{r}
head(sort(unique(tabela[, ocorrencia_longitude])), 40)
```
Texto...

Texto 2...

```{r}
#tabela_ = data.table::copy(tabela)

### Caso 1 - Espaço (Lat e Log)
tabela[, ocorrencia_latitude := as.numeric(gsub(" ", "", ocorrencia_latitude))]
tabela[, ocorrencia_longitude := as.numeric(gsub(" ", "", ocorrencia_longitude))]

### Caso 2 - Vírgula (Só Lat)
tabela[, ocorrencia_latitude := as.numeric(gsub(",", ".", ocorrencia_latitude))]

### Caso 3 - Duplo negativo (Só Log)
tabela[, ocorrencia_longitude := as.numeric(gsub("--", "-", ocorrencia_longitude))]

### Caso 4 - Número todo cagado (Lat e Log)


### Caso Normal
# tabela_[, `:=`(
  # ocorrencia_latitude = as.numeric(ocorrencia_latitude)
  # ocorrencia_longitude = as.numeric(ocorrencia_longitude),
# )]
```


Após tratamentos:

```{r}
head(sort(unique(tabela[, ocorrencia_latitude])), 135)
```

```{r}
head(sort(unique(tabela[, ocorrencia_longitude])), 40)
```

Após tratamentosd

# Análises

Em construção, maybe

## Número de ocorrências pelo tempo

```{r}
# Seleciona as colunas relevantes, e dá um distinct para evitar observações duplicadas
ocorrencias_tempo_prep <- unique(tabela[, .(ocorrencia_dia, codigo_ocorrencia)])

# 
ocorrencias_tempo <- ocorrencias_tempo_prep[, .(N = .N), keyby = c("ocorrencia_dia")]
```

